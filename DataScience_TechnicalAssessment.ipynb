{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigitercero/DataScience-TechnicalAssessment/blob/main/DataScience_TechnicalAssessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "25017e37-e546-4e4c-b279-8d8718c3f37b",
      "metadata": {
        "id": "25017e37-e546-4e4c-b279-8d8718c3f37b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91fa19c7-28da-4318-b5bb-23ffdd21cf54",
      "metadata": {
        "id": "91fa19c7-28da-4318-b5bb-23ffdd21cf54"
      },
      "source": [
        "# Cartful Solutions - Technical test - Data Science"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b86dad8-052e-4fe7-b209-fb843dd581d2",
      "metadata": {
        "id": "3b86dad8-052e-4fe7-b209-fb843dd581d2"
      },
      "source": [
        "### Important\n",
        "\n",
        "1. write the code for every answer, store the answers as variables and print the variable in the notebook. The process to answer each task, should be in the notebook.\n",
        "2. Answer the tasks in the order presented."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd9dc86-4330-410e-b17f-3e3e4f3d3826",
      "metadata": {
        "id": "3cd9dc86-4330-410e-b17f-3e3e4f3d3826"
      },
      "source": [
        "## 0. Dataset load and context comprehension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98acff52-4674-4733-947b-064abb9007c9",
      "metadata": {
        "id": "98acff52-4674-4733-947b-064abb9007c9"
      },
      "source": [
        "### Tasks\n",
        "* Split dataset into train and test for independent and dependent variables\n",
        "* Convert independent variables for train and test sets into float numbers\n",
        "* What is the range of values for the independent variables\n",
        "* Considering dataset context, why are the independent variables within that range, what do values represent?\n",
        "* Convert the independent variable values within the range [0,1]\n",
        "* What is the range of values of the dependent variables?\n",
        "* Considering dataset context, why are the dependent variables within that range, what do values represent?\n",
        "* Based on the data, what is the dimension of the input vectors\n",
        "* Choose a random vector from the test set, the element is flattenized, reshape it into the original shape with 1 channel following the dimension height x width x channel\n",
        "* Visually display the 2D vector using matplotlib imshow module. What value is displayed?\n",
        "* Based on independent variable dimension, how many color channels does the dataset use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "721216f2-b978-4e5e-91f1-40447303bd16",
      "metadata": {
        "id": "721216f2-b978-4e5e-91f1-40447303bd16"
      },
      "outputs": [],
      "source": [
        "dataset = tf.keras.datasets.mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "d1d15b4e-417d-47c3-a781-7efae4124140",
      "metadata": {
        "id": "d1d15b4e-417d-47c3-a781-7efae4124140"
      },
      "outputs": [],
      "source": [
        "# Note: The data is being loaded, following the structure ((train), (test)) sets\n",
        "data = dataset.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "EtUywimuyxjp"
      },
      "id": "EtUywimuyxjp",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "77dc81a2-3388-4573-833a-cbd5444167ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77dc81a2-3388-4573-833a-cbd5444167ee",
        "outputId": "ef5659a4-dcc8-4283-e167-c8c4844e8005"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# What is the range of values for the independent variables\n",
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "b0fb7859-429e-4716-b1d0-6ebae32a1935",
      "metadata": {
        "id": "b0fb7859-429e-4716-b1d0-6ebae32a1935"
      },
      "outputs": [],
      "source": [
        "# Considering dataset context, why are the independent variables within that range, what do values represent?\n",
        "\n",
        "#represent hand number since 0 to 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "f2351fac-280c-42f2-b2cb-df61ce921266",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2351fac-280c-42f2-b2cb-df61ce921266",
        "outputId": "1bf35665-edc4-463d-b357-09b87e40bcd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# What is the range of values of the dependent variables?\n",
        "train_labels.shape\n",
        "y_unique_value = set(train_labels)\n",
        "y_unique_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "d6f395af-719e-4c0c-b7d8-9a9a1fb9ca76",
      "metadata": {
        "id": "d6f395af-719e-4c0c-b7d8-9a9a1fb9ca76"
      },
      "outputs": [],
      "source": [
        "# Considering dataset context, why are the dependent variables within that range, what do values represent?\n",
        "\n",
        "\n",
        "# depend variable represent a label for each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "a3db183e-193b-4fb1-b322-e4eef22c18af",
      "metadata": {
        "id": "a3db183e-193b-4fb1-b322-e4eef22c18af"
      },
      "outputs": [],
      "source": [
        "# Convert independent variables for train and test sets into float numbers\n",
        "\n",
        "x_train = train_data.astype('float32')\n",
        "x_test = test_data.astype('float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "36a05c03-9fc9-44d5-92bd-7f979b4d0b7a",
      "metadata": {
        "id": "36a05c03-9fc9-44d5-92bd-7f979b4d0b7a"
      },
      "outputs": [],
      "source": [
        "# Convert input variables within range [0,1]\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "9fd3e32f-8555-495c-91b6-989e7c6dd375",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd3e32f-8555-495c-91b6-989e7c6dd375",
        "outputId": "869b941d-967c-4d77-b2c6-e3be6b8286d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "# Based on the data, what is the dimension of the input vectors?\n",
        "\n",
        "# Input dimension is 28X28 \n",
        "\n",
        "28*28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "c7788499-b7e3-4cdb-9388-893401cf2539",
      "metadata": {
        "id": "c7788499-b7e3-4cdb-9388-893401cf2539"
      },
      "outputs": [],
      "source": [
        "# Choose a random vector from the test set\n",
        "# Flattenize the vector using vector.flatten(), what is this vector shape?\n",
        "# Reshape it into the original shape with 1 color channel following the dimension height x width x channel\n",
        "\n",
        "flatten_img = x_train[3].flatten().shape\n",
        "\n",
        "reshape = x_train[3].reshape(28,28,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "555638fe-b5ea-4593-a3b7-7644bce9671c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "555638fe-b5ea-4593-a3b7-7644bce9671c",
        "outputId": "1c9e3348-aa4e-4884-d23a-41faf417c745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f54d8546e80>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visually display the 2D vector using matplotlib imshow module. What value is displayed?\n",
        "plt.imshow(x_train[55])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "3e8293d9-3c69-4240-ba3f-019a65e19a8c",
      "metadata": {
        "id": "3e8293d9-3c69-4240-ba3f-019a65e19a8c"
      },
      "outputs": [],
      "source": [
        "# Based on independent variable dimension, how many color channels does the dataset use?\n",
        "\n",
        "# data set just one channels It uses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "3dee29ea-9cee-4ad6-826c-23fa56973aa6",
      "metadata": {
        "id": "3dee29ea-9cee-4ad6-826c-23fa56973aa6"
      },
      "outputs": [],
      "source": [
        "# Please make sure that all tasks have been answered."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80f0e429-b2c0-4c8e-bcdb-151ddba191fb",
      "metadata": {
        "id": "80f0e429-b2c0-4c8e-bcdb-151ddba191fb"
      },
      "source": [
        "## 1. Tensorflow implementation\n",
        "\n",
        "Using the code below, answer and implement the solution to each question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "5e0e57c3-8df2-4071-804e-e1ff230ac070",
      "metadata": {
        "id": "5e0e57c3-8df2-4071-804e-e1ff230ac070"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(\n",
        "        input_shape=(1, 1)\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=None,\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=None,\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=None,\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=None,\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=None,\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    # Output layer (missing)\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2f00d4-28c6-47a1-8523-63c5b9f4ce0e",
      "metadata": {
        "id": "ea2f00d4-28c6-47a1-8523-63c5b9f4ce0e"
      },
      "source": [
        "### Tasks\n",
        "* Update model input tensor shape, with the shape of the dataset input vectors.\n",
        "\n",
        "\n",
        "1.   **updated input layer with (28,28)**\n",
        "\n",
        "\n",
        "* Choose and set activation function for hidden layers and explain why you chose that option, update the model with that activation function.\n",
        " \n",
        "\n",
        "1.   *Choosed Relu because contain derivate function is perfect to calaculated weight in back prpagation process, avoid negatives number*\n",
        "\n",
        "\n",
        "* Would you add bias to the layers? Explain why or why not, and add bias to all layers if you answered yes.\n",
        "1.  This model dont have a lot classses to use bias \n",
        "* Update number of nodes in each layer to match the following rule:\n",
        "    - First hidden layer, should be the same number of nodes as the input layer flattenized. Hint: nodes = h x w\n",
        "    - Each layer should be 1/2x of the previous layer nodes (x = previous layer nodes). This exception is for the output layer that will be added in the next step.\n",
        "* Add an output layer:\n",
        "    - How many nodes will have the output layer based on the dataset? Specify the number of nodes in the output layer in the model.\n",
        "1. We have 10 labels to classificate\n",
        "    - Which activation function would you use for the output layer, explain why, and add it to the model.\n",
        "1. softmax its distribution are use to classification problem and where the sum of the probabilities is 1\n",
        "* Train the model using the training set\n",
        "* Evaluate the model accuracy\n",
        "    - What does the loss mean? What is the loss for the model?\n",
        "    It represents the difference between the predicted values and the true values of the training data, and is typically expressed as a scalar value that is minimized during training.\n",
        "    - What does accuracy mean? What is the accuracy of the model?\n",
        "    I t represents the proportion of correctly classified instances to the total number of instances.\n",
        "* Why would you add dropout layers to the model?\n",
        "- Avoid overffiting \n",
        "* Add a dropout layer previous the output layer with 20% dropout, compare the 2 models loss and accuracy. Which one was better?\n",
        "- first model look better I compared val_accuracy and loss value\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input 28,28*\n",
        "# used relu because all information is 0 when data is leess 0 and get original values if x > 0 then Its a betterr function to back propagation because relu has can be derevate \n",
        "#Yes i can, but this data set is not complex\n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(\n",
        "        input_shape=(28, 28)\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=784,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=392,\n",
        "        activation='relu',\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=196,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=98,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=49,\n",
        "        activation=None,\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        10, activation='softmax'\n",
        "    )\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kVVKzNs0_xlx"
      },
      "id": "kVVKzNs0_xlx",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dropout = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(\n",
        "        input_shape=(28, 28)\n",
        "    ),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=784,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=392,\n",
        "        activation='relu',\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=196,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=98,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=49,\n",
        "        activation='relu',\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(\n",
        "        10, activation='softmax'\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "HmgHszF2HiaD"
      },
      "id": "HmgHszF2HiaD",
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7b234b63-277e-432a-b4a0-e482b71d3846",
      "metadata": {
        "tags": [],
        "id": "7b234b63-277e-432a-b4a0-e482b71d3846"
      },
      "source": [
        "# 2. Model compilation\n",
        "\n",
        "### Tasks\n",
        "- Explain which loss metric would you use for this dataset where you expect to classify inputs.\n",
        "- Compile the model with that loss metric.\n",
        "\n",
        "# 3. Model evaluation\n",
        "\n",
        "### Tasks\n",
        "- Evaluate the model loss and accuracy.\n",
        "- Build confussion matrix for the model that has the dropout layer, and explain the confusion matrix relevant metrics."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical_crossentropy\n",
        "\n",
        "#is used because categorical_crossentropy is ajusted to a lot categorical output is used to more than 2\n",
        "\n",
        "callback_early = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience=3, mode = \"auto\")"
      ],
      "metadata": {
        "id": "JDqWkEnNFm8V"
      },
      "id": "JDqWkEnNFm8V",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "c743a2af-7b0e-4248-9844-c09f29407db2",
      "metadata": {
        "id": "c743a2af-7b0e-4248-9844-c09f29407db2"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_dropout.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_IyoWe7X8YW",
        "outputId": "9257f96a-e802-4113-ecb0-ce5a8811bcc8"
      },
      "id": "Z_IyoWe7X8YW",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "80f30379-893e-4ddf-9359-3865a400a8ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80f30379-893e-4ddf-9359-3865a400a8ce",
        "outputId": "4af3a5aa-6a2b-40c9-cddb-337557f9b268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1521 - accuracy: 0.9716 - val_loss: 0.2337 - val_accuracy: 0.9678\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1754 - accuracy: 0.9671 - val_loss: 0.3138 - val_accuracy: 0.9425\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1294 - accuracy: 0.9741 - val_loss: 0.1889 - val_accuracy: 0.9731\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9805 - val_loss: 0.1921 - val_accuracy: 0.9736\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0864 - accuracy: 0.9839 - val_loss: 0.1644 - val_accuracy: 0.9756\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0742 - accuracy: 0.9849 - val_loss: 0.2116 - val_accuracy: 0.9687\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0564 - accuracy: 0.9887 - val_loss: 0.1768 - val_accuracy: 0.9817\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0675 - accuracy: 0.9880 - val_loss: 0.1623 - val_accuracy: 0.9777\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0554 - accuracy: 0.9888 - val_loss: 0.1928 - val_accuracy: 0.9757\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0457 - accuracy: 0.9904 - val_loss: 0.2500 - val_accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54d8349b80>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "# Fit the model with the train set, use 10 epochs\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n",
        "model.fit(x_train, \n",
        "          y_train, \n",
        "          callbacks = [callback_early],\n",
        "          epochs=10, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dropout.fit(x_train, y_train, callbacks = [callback_early],epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-IXRXVfIJjQ",
        "outputId": "15a0338a-a764-4c13-f0ff-e98a06642a91"
      },
      "id": "4-IXRXVfIJjQ",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.8353 - accuracy: 0.7638 - val_loss: 0.2565 - val_accuracy: 0.9489\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4000 - accuracy: 0.9057 - val_loss: 0.2353 - val_accuracy: 0.9553\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3144 - accuracy: 0.9261 - val_loss: 0.2529 - val_accuracy: 0.9477\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2753 - accuracy: 0.9338 - val_loss: 0.1765 - val_accuracy: 0.9620\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2441 - accuracy: 0.9437 - val_loss: 0.1818 - val_accuracy: 0.9628\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2303 - accuracy: 0.9484 - val_loss: 0.1965 - val_accuracy: 0.9666\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2260 - accuracy: 0.9478 - val_loss: 0.1652 - val_accuracy: 0.9678\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2074 - accuracy: 0.9528 - val_loss: 0.1758 - val_accuracy: 0.9700\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1871 - accuracy: 0.9590 - val_loss: 0.1651 - val_accuracy: 0.9717\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1951 - accuracy: 0.9566 - val_loss: 0.1562 - val_accuracy: 0.9700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54de642a60>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "585d2cf9-59b0-48f9-bebf-b6e7e8631960",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "585d2cf9-59b0-48f9-bebf-b6e7e8631960",
        "outputId": "4272c5b0-e750-4f77-feab-c6c19b5ace3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.2500 - accuracy: 0.9766 - 662ms/epoch - 2ms/step\n",
            "Test loss: 0.2500, Test accuracy: 0.9766\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model with verbose=2 to know loss and accuracy metrics for the test set\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "# Build the confusion matrix\n",
        "confusion_mtx = tf.math.confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(confusion_mtx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trrqKdsAFfCX",
        "outputId": "86f2e20f-8947-463c-d40b-27ce35caf853"
      },
      "id": "trrqKdsAFfCX",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "tf.Tensor(\n",
            "[[ 974    1    1    1    0    0    1    0    0    2]\n",
            " [   1 1119    5    1    0    0    1    0    8    0]\n",
            " [   9    0 1008    0    1    0    0    6    8    0]\n",
            " [   0    1    9  978    0    6    0    5    5    6]\n",
            " [   2    2    2    0  953    0    4    7    0   12]\n",
            " [   3    0    1    6    0  849    2    1   12   18]\n",
            " [   6    3    0    0    2    7  933    0    4    3]\n",
            " [   3    1    8    0    0    0    0 1011    1    4]\n",
            " [   3    6    3    1    0    3    0    3  945   10]\n",
            " [   1    1    1    1    4    2    0    3    0  996]], shape=(10, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17812bf6-e87f-4a5e-8091-dd11c4089e93",
      "metadata": {
        "id": "17812bf6-e87f-4a5e-8091-dd11c4089e93"
      },
      "source": [
        "# 4. Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb13e6d-0ac9-49ef-a109-3c89ad1968db",
      "metadata": {
        "id": "9fb13e6d-0ac9-49ef-a109-3c89ad1968db"
      },
      "source": [
        "### Tasks\n",
        "- What is the category that gets classified incorrectly the most\n",
        "    - what would you do to solve this issue?\n",
        "* Get the first 10 elements of the dependent variable test set. Suppose these values are the only ones that we would like to classify.\n",
        "    - Considering our Neural Network architecture, how many nodes would the output layer have if we train with this scenario?\n",
        "    - Considering our Neural Network architecture, if we increase the input tensor shape to 45x45, how many nodes would each hidden layer have?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the confusion matrix\n",
        "confusion_mtx = tf.math.confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "# Convert the tensor to a NumPy array for easier indexing\n",
        "confusion_mtx = confusion_mtx.numpy()\n",
        "\n",
        "# Compute the sum of off-diagonal elements for each row\n",
        "sums = np.sum(confusion_mtx - np.diag(np.diag(confusion_mtx)), axis=1)\n",
        "\n",
        "# Find the index of the row with the largest sum\n",
        "max_idx = np.argmax(sums)\n",
        "\n",
        "# Print the category with the largest number of misclassifications\n",
        "print(f\"Category {max_idx} has the largest number of misclassifications.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txQOn7rJKnGx",
        "outputId": "d8c809a9-1740-4adb-8666-33fbdbe7f259"
      },
      "id": "txQOn7rJKnGx",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category 6 has the largest number of misclassifications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can collect more traine data for that category or we can use data augmentation, to expand data set\n"
      ],
      "metadata": {
        "id": "v5JPFOX3LFzE"
      },
      "id": "v5JPFOX3LFzE"
    },
    {
      "cell_type": "code",
      "source": [
        "# We can collect more traine data for that category or we can use data augmentation, to expand data set solve categorical issue"
      ],
      "metadata": {
        "id": "gE5R_6OhL1pf"
      },
      "id": "gE5R_6OhL1pf",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_10 = test_labels[:10]\n",
        "print(set(first_10))\n",
        "print(f'output layer {len(set(first_10))}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrOtPqy4Mfct",
        "outputId": "8855fb74-f3ea-41c7-c179-1eea01bd3426"
      },
      "id": "FrOtPqy4Mfct",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 4, 5, 7, 9}\n",
            "output layer 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we increase the input tensor shape to 45x45, the number of input nodes in the first layer of our neural network would be 2025 (45 x 45).\n",
        "I increased scale the number of nodes in each layer proportional to the increase in input size.\n"
      ],
      "metadata": {
        "id": "IFAZWltJL0ke"
      },
      "id": "IFAZWltJL0ke"
    },
    {
      "cell_type": "code",
      "source": [
        "print(784 * (45/28)\n",
        ", 784/2 * (45/28)\n",
        ", 784/2/2 * (45/28)\n",
        ", 784/2/2/2 * (45/28)\n",
        ", 784/2/2/2/2 * (45/28)\n",
        ", sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOP6Ex_nOW-r",
        "outputId": "e541129d-0930-4435-9c3a-7a02fa594d12"
      },
      "id": "MOP6Ex_nOW-r",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1260.0\n",
            "630.0\n",
            "315.0\n",
            "157.5\n",
            "78.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1123b795-7185-4edf-8823-ea886916d609",
      "metadata": {
        "id": "1123b795-7185-4edf-8823-ea886916d609"
      },
      "source": [
        "# Theory questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18689e6e-8b27-46fa-9612-c52262185d9a",
      "metadata": {
        "id": "18689e6e-8b27-46fa-9612-c52262185d9a"
      },
      "source": [
        "a. Explain the difference between supervised and non-supervised algorithms.\n",
        "*Supervised algorithms are trained on labeled data*\n",
        "*non-supervised algorithms: are trained on ublabeled data*\n",
        "\n",
        "b. Explain 3 non-supervised algorithms\n",
        "\n",
        "\n",
        "\n",
        "1.   K-Means Clustering: K-Means is a clustering algorithm that groups similar data points together into a predetermined number of clusters. \n",
        "2.   Principal Component Analysis (PCA): PCA is a dimensionality reduction algorithm that reduces the number of features in a data set while retaining most of the variability in the original data,  can be used in place of the original features to perform tasks such as visualization, classification, or regression. \n",
        "3. Association Rule Mining: Association rule mining is a technique for discovering interesting relationships between variables in a large data set. The goal of this technique is to find patterns or rules that describe the co-occurrence of items in a data set\n",
        "\n",
        "\n",
        "\n",
        "c. Explain 3 supervised algorithms\n",
        "1. Linear Regression: The linear equation is learned using a training set of input-output pairs, and once the model is trained, it can be used to make predictions on new data.\n",
        "\n",
        "2. Decision Trees: The algorithm works by recursively partitioning the input space into subsets based on the values of the input features, until a stopping criterion is met. \n",
        "\n",
        "3. Support Vector Machines (SVMs): I like how to build this algorthm, we can use how neurone. The algorithm works by finding the hyperplane that separates the data into different classes or predicts the output value based on the input features. \n",
        "\n",
        "d. When analyzing statistical significance in hypothesis testing, considering a P value of 0.15, answer the following scenarios:\n",
        "\n",
        "    - What does it mean a p-value > 0.15?\n",
        "    - What does it mean a p-value = 0.15?\n",
        "    - What does it mean a p-value < 0.15?\n",
        "\n",
        "\n",
        "\n",
        "1.   value greater than 0.15 indicates that there is not enough evidence to reject the null hypothesis at the 0.05 significance level.\n",
        "2.   value equal to 0.15 means that there is a 15% chance of observing the test statistic if the null hypothesis is true.\n",
        "3.   value less than 0.15 means that there is strong evidence against the null hypothesis at the 0.05 significance level.\n",
        "\n",
        "\n",
        "    \n",
        "e. How would you overcome overfitting when training a Neural Network?\n",
        "\n",
        "therae are a lot way to overcome overfitting\n",
        "1. I prefered use Transfer learning to avoid overfitting\n",
        "2. Used Data augmetatation  to crease the size and versity of training set.\n",
        "3. Use regularization techniques: Regularization methods, such as L1 or L2 regularization, dropout, or early stopping, can help prevent overfitting by adding constraints to the network's weights and biases, or by stopping the training process early.\n",
        "4. Simplify the model architecture\n",
        "5. Keras tunner if we cant use transfer learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d463e0-d331-4045-8097-44e8f05ecb3a",
      "metadata": {
        "id": "13d463e0-d331-4045-8097-44e8f05ecb3a"
      },
      "source": [
        "# On completion\n",
        "\n",
        "Push this notebook to your personal repository and share the repository URL via email. Best of the luck."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hcldQluHTNql"
      },
      "id": "hcldQluHTNql",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow2_p310",
      "language": "python",
      "name": "conda_tensorflow2_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}